{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09f99af0-23e1-459d-a10a-71e34a79418d",
   "metadata": {},
   "source": [
    "## Text Embedding with OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36a40299-91f8-48fe-838b-7140ab6794fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf1b05bf-7837-4ded-8998-72a152b7d9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "from langchain_text_splitters.markdown import MarkdownHeaderTextSplitter\n",
    "from langchain_text_splitters.character import CharacterTextSplitter\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "import numpy as np\n",
    "from langchain_chroma import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "990285e8-a051-44b0-a7bf-8bae8ff44dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_docx = Docx2txtLoader(\"Introduction_to_Data_and_Data_Science.docx\")\n",
    "pages = loader_docx.load()\n",
    "\n",
    "md_splitter = MarkdownHeaderTextSplitter(headers_to_split_on = [(\"#\", \"Course Title\"), \n",
    "                                                                (\"##\", \"Lecture Title\")])\n",
    "pages_md_split = md_splitter.split_text(pages[0].page_content)\n",
    "\n",
    "for i in range(len(pages_md_split)):\n",
    "    pages_md_split[i].page_content = \" \".join(pages_md_split[i].page_content.split())\n",
    "\n",
    "char_splitter = CharacterTextSplitter(separator = \".\",\n",
    "                                      chunk_size = 500,\n",
    "                                      chunk_overlap = 50)\n",
    "pages_char_split = char_splitter.split_documents(pages_md_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ef308f6-abc7-4a35-a742-07200eaf2962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Final document chunks to embed: 20\n",
      "DEBUG: Persistence directory set to: ./vector-store\n"
     ]
    }
   ],
   "source": [
    "print(f\"DEBUG: Final document chunks to embed: {len(pages_char_split)}\")\n",
    "if not pages_char_split:\n",
    "    print(\"FATAL: Document list is empty. Debug splitting logic.\")\n",
    "    # Stop here if the list is empty\n",
    "\n",
    "# 2. Print the persistence path\n",
    "PERSIST_DIR = \"./vector-store\"\n",
    "print(f\"DEBUG: Persistence directory set to: {PERSIST_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d3c8f23-2543-4322-940e-586c590e0d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Analytics is essentially the application of logical and computational reasoning to the component parts obtained in an analysis. And in doing this you are looking for patterns and exploring what you could do with them in the future. Here, analytics branches off into two areas: qualitative analytics – this is using your intuition and experience in conjunction with the analysis to plan your next business move' metadata={'Course Title': 'Introduction to Data and Data Science', 'Lecture Title': 'Analysis vs Analytics'}\n",
      "\n",
      "page_content='You may use this intuition to decide on which styles of clothing to start selling. This would be qualitative analytics. But you might not know when to introduce the new collection. In that case, relying on past sales data and user experience data, you could predict in which month it would be best to do that. This is an example of using quantitative analytics' metadata={'Course Title': 'Introduction to Data and Data Science', 'Lecture Title': 'Analysis vs Analytics'}\n",
      "\n",
      "page_content='More importantly, it will be sufficient for your need to create quick and accurate analyses. However, if your theoretical preparation is strong enough, you will find yourself restricted by software. Knowing a programming language such as R and Python, gives you the freedom to create specific, ad-hoc tools for each project you are working on' metadata={'Course Title': 'Introduction to Data and Data Science', 'Lecture Title': 'Programming Languages & Software Employed in Data Science - All the Tools You Need'}\n"
     ]
    }
   ],
   "source": [
    "print(pages_char_split[3], end=\"\\n\\n\")\n",
    "print(pages_char_split[5], end=\"\\n\\n\")\n",
    "print(pages_char_split[18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bf90d66-c020-4651-9861-76abccfabb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = OpenAIEmbeddings(model = \"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59ab7ac3-dd42-48e4-863d-3a72a4971d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vector1 = embedding.embed_query(pages_char_split[3].page_content)\n",
    "#vector2 = embedding.embed_query(pages_char_split[5].page_content)\n",
    "#vector3 = embedding.embed_query(pages_char_split[18].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a70fe2f-7408-4e38-84d6-5fbefda5828d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Attempting to embed a single chunk...\n",
      "SUCCESS: Embedding worked! Vector dimension: 1536\n",
      "DEBUG: Proceeding to Chroma creation...\n"
     ]
    }
   ],
   "source": [
    "# Grab the content of the first chunk\n",
    "test_text = pages_char_split[0].page_content\n",
    "\n",
    "try:\n",
    "    print(\"DEBUG: Attempting to embed a single chunk...\")\n",
    "    # .embed_query() is for single text input, perfect for testing\n",
    "    test_vector = embedding.embed_query(test_text)\n",
    "    \n",
    "    # If successful, print confirmation\n",
    "    print(f\"SUCCESS: Embedding worked! Vector dimension: {len(test_vector)}\")\n",
    "    print(\"DEBUG: Proceeding to Chroma creation...\")\n",
    "\n",
    "except Exception as e:\n",
    "    # If it fails, the error will be printed, likely revealing an API issue\n",
    "    print(f\"FATAL: Embedding failed. Check OpenAI API Key/Network. Error: {e}\")\n",
    "    # Stop here if the embedding fails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcb4ab8-91c4-4aa6-a8b0-b627f1c7ba20",
   "metadata": {},
   "source": [
    "## Creating a Chroma Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb75534b-fe5e-47ac-829d-92d67d445f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VERIFICATION: Reloaded Chroma store count: 140 documents.\n",
      "SUCCESS: Documents were saved and can be reloaded.\n"
     ]
    }
   ],
   "source": [
    "vectorstore = Chroma.from_documents(documents = pages_char_split,\n",
    "                                    embedding = embedding,\n",
    "                                   persist_directory = \"./vector-store\" )\n",
    "# --- Verification Step ---\n",
    "# To verify the contents, you must reload the vector store from the disk.\n",
    "# NOTE: You must provide the same embedding function to load the store.\n",
    "reloaded_vectorstore = Chroma(\n",
    "    persist_directory=PERSIST_DIR,\n",
    "    embedding_function=embedding\n",
    ")\n",
    "\n",
    "# Use the internal _collection object to get the count\n",
    "count = reloaded_vectorstore._collection.count()\n",
    "print(f\"VERIFICATION: Reloaded Chroma store count: {count} documents.\")\n",
    "\n",
    "if count == 0:\n",
    "    print(\"FATAL: Chroma persistence failed or documents were not added.\")\n",
    "    print(f\"ACTION: Check folder '{PERSIST_DIR}' for files to confirm disk write attempt.\")\n",
    "else:\n",
    "    print(\"SUCCESS: Documents were saved and can be reloaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5b311c0-45b2-44ff-bc16-77cfad9736c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore_from_directory = Chroma(persist_directory = \"./vector-store\",\n",
    "                                   embedding_function = embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be6bbd5-dc4c-4989-b9db-42d7bec4ed9d",
   "metadata": {},
   "source": [
    "## Manage Documents within the Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4f2dc48-c05e-4abe-ad67-6571ea761295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['a4e8e867-e800-4934-837e-27ccb2076f23'],\n",
       " 'embeddings': None,\n",
       " 'documents': ['Alright! So… Let’s discuss the not-so-obvious differences between the terms analysis and analytics. Due to the similarity of the words, some people believe they share the same meaning, and thus use them interchangeably. Technically, this isn’t correct. There is, in fact, a distinct difference between the two. And the reason for one often being used instead of the other is the lack of a transparent understanding of both. So, let’s clear this up, shall we? First, we will start with analysis'],\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'documents'],\n",
       " 'data': None,\n",
       " 'metadatas': [{'Lecture Title': 'Analysis vs Analytics',\n",
       "   'Course Title': 'Introduction to Data and Data Science'}]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore_from_directory.get(ids = \"a4e8e867-e800-4934-837e-27ccb2076f23\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be1fd81-0a83-406d-a7d1-b20a5f29f832",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3f2031-4020-47a5-a359-3756fe2f1de2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "langchain_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
